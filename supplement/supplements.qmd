---
bibliography: ../manuscript/references.bib
csl: ../manuscript/apa.csl
format: 
  docx:
    reference-doc: ../manuscript/reference-doc.docx
    toc: true
    toc-location: left
    toc-title: Table of Contents
output:
  officedown::rdocx_document:
    page_margins:
      bottom: 1
      footer: 0
      gutter: 0
      header: 0.5
      left: 1
      right: 1
      top: 1
    plots:
      align: center
      caption:
        pre: 'Figure '
        sep: '. '
        style: Image Caption
    tables:
      caption:
        pre: 'Table '
        sep: '. '
        style: Table Caption
  pdf_document: default
  word_document: default
editor: 
  markdown: 
    wrap: sentence
---
```{r include=FALSE}
load("../preregistrations/1_pilot/analysis_objects/supp_section2.Rdata")
load("../preregistrations/2_study1/analysis_objects/supp_section2.Rdata")
load("../preregistrations/3_study2/analysis_objects/supp_section2.Rdata")
load("../data/1_pilot/mod_fit_flanker.RData")
load("../data/2_study1/ssp_fit.RData")
load("../data/3_study2/ssp_fit.RData")
load("../preregistrations/1_pilot/analysis_objects/DDM_objects.Rdata")
load("../preregistrations/1_pilot/analysis_objects/hddm_recovery_plots.RData")

load("../manuscript/pilot_staged_results.RData")
load("../manuscript/study1_staged_results.RData")
load("../manuscript/study2_staged_results.RData")
load("../manuscript/pooled_staged_results.RData")

library(flextable)
library(tidyverse)
library(patchwork)

# set up flextable for tables
set_flextable_defaults(
  font.family = "Times", 
  font.size = 10,
  font.color = "black",
  line_spacing = 1,
  padding.bottom = 1, 
  padding.top = 1,
  padding.left = 1,
  padding.right = 1
)

knitr::opts_chunk$set(
  echo = F,
  fig.align = "center",
  fig.pos = "!t", 
  out.extra = "",
  fig.show = "asis",
  message = FALSE,
  tab.topcaption = T,
  warning = FALSE
)
```


# Section 1. Descriptions of exploratory measures

The exploratory measures described in section 1.1 - 1.5 were collected in all three studies.
The exploratory measure described in section 1.6 was collected on Study 2 only.

The following exploratory measures were collected in all three studies.

## 1.1. Current state 
We assessed state anxiety during the experiment using the state subscale of the State-Trait Anxiety Inventory [STAI-S\; @spielberger_1999]. 
The STAI-S contains 20 short items measuring current anxiety (e.g., "I feel tense"). 
Participants rated each item on a scale of 1 (not at all) to 4 (very much so). 
An overall state anxiety variable was computed by averaging across the 20 unweighted items.

In addition, participants answered five questions relating to specific states: "Are you currently sick?" (rated as yes or no); "Have you eaten a full meal today?" (rated as yes or no); "How hungry do you feel right now?" (rated from 1 (not at all) to 5 (very hungry)); "How well did you sleep last night?" (rated from 1 (very poorly) to 5 (very well)); "How rested or refreshed did you feel when you woke up this morning?" (rated from 1 (not at all) to 5 (very rested)). We computed an overall sleep deprivation composite by standardizing and averaging across the two unweighted sleep-related items.

## 1.2. Poverty exposure 
Participants' perceived level of resource scarcity before age 13 was measured using seven items (e.g., "Your family had enough money to afford the kind of home you all needed"). 
Participants rated each item on a scale from 1 (never true) to 5 (very often true). 
Scores for the first six items were reverse coded so that higher scores indicated more perceived resource scarcity. 
The items were averaged together to create an unweighted composite scale.

In addition, we measured several indicators of objective SES before age 13. 
First, participants separately indicated the highest education of their mother and father on an 8-point scale: 'some high school', 'GED', 'high school diploma', 'some college but no college degree', associate's  degree', 'bachelor's degree', 'master's  degree', or 'doctoral or lab degree'. 
The mother and father education level were averaged to create an overall unweighted parental education composite. 
Participants also indicated their family's household income before age 13 on a 6-point scale: 'less than \$ 25k/year', '\$25k - \$49k/year, '\$50 - \$74k/year', '\$75 - \$99k/year', '\$100 - \$149k/year', 'more than \$150k/year'. 
Scores were reverse coded so that higher scores indicated higher levels of poverty.

We created a composite score of poverty exposure before age 13 by averaging together the standardized scores of perceived level of resource scarcity, overall parental education, and household income.

## 1.3. Impulsivity 
We assessed impulsivity with the Motor Impulsivity subscale of the Barrett Impulsivity Scale [BIS short form\; @patton_1995; @spinella_2007]. 
The Motor Impulsivity subscale of the BIS consists of five items (e.g., "I do things without thinking").
We did not include the Non-planning subscale because it overlapped substantially with the Future Orientation Scale described below. 
In addition, we did not include the Attention impulsivity subscale because it included items which we deemed to be mostly irrelevant for our target population (e.g., "I 'squirm' at plays or lectures"). 
We changed the original 4-point rating scale (rarely/never to almost always) to a 5-point rating scale ranging from 1 (never true) to 5 (very often true). 
An overall impulsivity variable was computed by averaging the five unweighted items.

## 1.4. Future Orientation 
We assessed future orientation with an adapted version of the Future Orientation Scale [FOS\; @steinberg_2009]. 
The original scale consists of 15 sets of opposing items separated by "BUT" (e.g., "Some people like to plan things out one step at a time BUT other people like to jump right into things without planning them out beforehand"). 
Participants first choose the item that best matches their general preference, and then indicate whether the statement is "really true" or "somewhat true". 
We adapted this format in a couple of ways. 
First, we converted the two statements per item to a single statement by picking the statements in the original right-hand column. 
Second, we adapted the 15 statements from a third-person to a first-person format. 
These changes were made in an attempt to reduce the cognitive load of the items. 
We worried that people with less formal education or who were sitting in a noisier environment would struggle with the length of the original items. 

In addition, item 8 of the original scale ("[...] other people would rather spend their money right away on something fun than save it for a rainy day") was changed to "I'd rather spend money right away than save it for a rainy day" (i.e., dropping the phrase "on something fun") to make it more general with regard to the thing that money is spent on. 
For people from adversity, spending money right now instead of saving it for the future might often be born out of necessity (e.g., having just enough money for food and shelter; being in debt) instead of a failure to delay gratification. 
Finally, the rating scale was adapted from the original 4-point scale (ranging from really true for the left-hand statement to really true for the right-hand statement) to a 5-point scale ranging from 1 (never true) to 5 (very often true).
An overall future orientation variable was computed by averaging the 15 unweighted items.

## 1.5. Depressive symptoms 
We assessed depressive symptoms during the past week using the Center for Epidemiologic Studies Depression Scale [CESD\; @radloff_1977]. 
The scale consists of 20 items (e.g., "I do things without thinking"). 
Participants rate each item on a scale of 1 (rarely or none of the time (less than 1 day)) to 4 (most or all of the time (5-7 days)). 
An overall depression variable was computed by averaging the 20 unweighted items.

## 1.6. Attentional style

We measured attentional style using the Attentional Style Questionnaire [ASQ\; @calster_2018] (See [Table S7](#appendix).
The ASQ measures self-reported attentional style, with seven items asking about the participant's propensity for internally oriented attention (e.g., "During an activity, unrelated mmental images and thoughts come to my mind") and seven items about externally oriented attention (e.g., "I am easily drawn to new stimuli (for example, voices of people passing by, as sound in the house, ...) that are not relevant to a task I am doing"). 
Where necessary, items were recoded in such a way that they reflected *distractibility* by internal and external stimuli, respectively, with higher scores reflecting a higher degree of distractibility.
We computed unweighted averages separately for internally oriented attention and externally oriented attention.

# Section 2. Exploratory analyses

## 2.1. Consistency in unpredictability measures

### 2.1.1. Pilot

The EFA yielded five factors based on parallel analysis (see Table S1).
Based on their contents, we labelled these factors (1) Daily unpredictability; (2) Household routine; (3) Spatial unpredictability; (4) Chaos/clutter; (5) Social unpredictability.

```{r}
#| tab.id: tableS1
#| results: markup
pilot_efa_table 
```

### 2.1.2 Study 1

Similar to the Pilot, the EFA yielded five factors based on parallel analysis.
We plotted the factor loadings of each factor in the Pilot against those in Study 1 to investigate their correspondence (See Figure SX).
In general, individual items largely loaded on the same factors, and the sizes of their loadings were also comparable.
The items from the CHAOS were found to be most unstable, with many showing a loading < .32 in one of the two studies.

```{r}
#| label: figureS1
#| dpi: 600
#| fig.width: 7
#| fig.height: 7
#| fig-cap: | 
#|   **Figure S1.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
study1_efa_fig 
```
## 2.2. Bivariate correlations between future orientation and impulsivity with attention tasks

Table S2 shows bivariate correlations between self-reported depression, impulsivity, future orientation, and SES with each of the Flanker SSP parameters and the Global-Local drift rate difference.
Participants who reported more depressive symptoms had a lower strength of perceptual input.
Participants who reported more impulsivity had a lower strength of perceptual input, higher interference, as well as a more holistic processing style.
Participants who were more future oriented had a higher strength of perceptual input and a more detail-oriented processing style, without an association with interference.

```{r}
#| tab.id: tableS3
#| results: markup
supp_cor_table |> 
  autofit()
```

# Section 3. Model fit

## 3.1. Pilot 

## 3.1.1 Cueing and Change Detection Task

In our initial, preregistered approach, DDM models for the Cueing and Change Detection Task were fit with the fast-dm-30 software [@voss_2015] using maximum likelihood (ML) estimation.
For both tasks, we started out with a model that freely estimated all parameters, and then fit additional models with an increasing number of constrained parameters.
We compared model fit using the Bayesian information criterion (BIC), for which smaller values indicate better fit.
For the Change Detection Task, the most simple model provided the best fit.
This model freely estimated the drift rate, non-decision time, and boundary separation, and fixed all other parameters.

For the Cued Attention Task, three models provided comparable model fit.
However, all three models showed estimation problems, especially with regard to the boundary separation.
Specifically, boundary separation estimates for several participants ended up at an upper boundary of 10, indicating that they were not recovered well.
Based on subsequent external input, we fit an additional model using Kolmogorov-Smirnov (KS) estimation instead of ML estimation, additionally estimating the inter-trial variability parameter of the non-decision time.
This improved parameter estimation (see Figure SX).

```{r}
#| label: figureS2
#| dpi: 600
#| fig.width: 7
#| fig-cap: | 
#|   **Figure S2.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
cueing_DDM_results_mod9 |> 
  select(starts_with("cueing"), -cueing_ks_fit) |> 
  rename(
    "a" = cueing_ks_a,
    "v - cued" = cueing_cued_ks_v,
    "v - neutral" = cueing_neutral_ks_v,
    "t - cued" = cueing_cued_ks_t0,
    "t - neutral" = cueing_neutral_ks_t0,
  ) |> 
  pivot_longer(everything(), names_to = "parameter", values_to = "Estimate") |> 
  ggplot(aes(Estimate)) +
  geom_histogram() +
  facet_wrap(~parameter, scales = 'free') +
  theme_classic()
```
Finally, we switched to estimation using Hierarchical Bayesian DDM (HDDM) for our final analyses.
The main reason for this step was that although KS estimation seemed to work well, we had fewer trials than is typically recommended for this estimation technique [@lerche_2017].
An advantage of HDDM is that it uses group-level estimates to inform and constrain individual-level estimates.
This is especially useful in cases such as ours, where we have a large sample size but relatively few trials per participant.

The HDDM models were fit using the *runjags* package [@denwood_2016], using code from @johnson_2017.
All models were fit using three Markov Chain Monte Carlo (MCMC) chains.
Each of these chains started with 2,000 burn-in samples, followed by 10,000 additional samples.
To decrease the total size of the model, every 10th sample was retained, resulting in a posterior sample of 3,000 samples.

Model convergence was assessed (1) by visually inspecting the traces, which should not contain any drifts or large jumps (see Figure SX and SX); (2) through simulation. Specifically, we used each participant's DDM estimates to simulate 100 RT and accuracy estimates (per condition). The distributions of the participant's true RTs and their simulated RTs were assessed through bivariate correlations at the 25th, 50th and 75th percentile (See Figure SX and SX).
We made the same comparison for mean accuracy levels (See Figure SX and SX).

<br>

```{r}
#| label: figureS3
#| dpi: 600
#| fig.width: 7
#| fig-cap: | 
#|   **Figure S3. ** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
pilot_traces_cueing
```

<br>

```{r}
#| label: figureS4
#| dpi: 600
#| fig.width: 7
#| fig-cap: | 
#|   **Figure S4.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
pilot_recov_rt_cueing
```

<br>

```{r}
#| label: figureS5
#| dpi: 600
#| fig.width: 7
#| fig-cap: | 
#|   **Figure S5.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
pilot_recov_acc_cueing
```

<br>

```{r}
#| label: figureS6
#| dpi: 600
#| fig.width: 7
#| fig-cap: | 
#|   **Figure S6.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
pilot_traces_change
```

<br>

```{r}
#| label: figureS7
#| dpi: 600
#| fig.width: 7
#| fig-cap: | 
#|   **Figure S7.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
pilot_recov_rt_change
```

<br>

```{r}
#| label: figureS8
#| dpi: 600
#| fig.width: 7
#| fig-cap: | 
#|   **Figure S8.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
pilot_recov_rt_cueing
```

<br>

## 3.1.2 Flanker

To fit the SSP model to the Flanker data, we followed recommendations by @grange_2016.
First, we searched for the optimal set of starting values.
For each participant, we used 50 sets of starting parameters with a variance of 20 for each, simulating 1,000 trials.
After finding the optimal starting values, we fit the final model based on 50,000 simulated trials.
Model fit was assessed through simulation.
For each participant, we simulated 50,000 trials.
We then calculated correlations between observed and simulated RTs at the 25th, 50th, and 75th percentile, as well as between observed and simulated mean accuracy.
As can be seen in Figure SX and Figure SX, we observed high agreement between observed and simulated RTs and accuracy rates.

<br>

```{r}
#| label: figureS9
#| dpi: 600
#| fig.width: 7
#| fig-cap: | 
#|   **Figure S9.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
qq_data_flanker <- left_join(predicted_quantiles_flanker, observed_quantiles_flanker)

qq_flanker_rt <- ggplot(qq_data_flanker) +
  geom_point(aes(quan_rt_obs, quan_rt_pred)) +
  geom_abline(slope = 1, intercept = 0) +
  facet_grid(congruency~quantile) +
  labs(
    x = "\nObserved RT",
    y = "Predicted RT\n",
    title = "Flanker Task"
  ) +
  theme_classic()

qq_flanker_rt
```

<br>

```{r}
#| label: figureS10
#| dpi: 600
#| fig.width: 7
#| fig-cap: | 
#|   **Figure S10.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
qq_flanker_acc <- ggplot(qq_data_flanker) +
  geom_point(aes(prop_acc_obs, prop_acc_pred)) +
  geom_abline(slope = 1, intercept = 0) +
  facet_grid(congruency~quantile) +
  expand_limits(x = 0, y = 0) +
  labs(
    x = "\nObserved Acc",
    y = "Predicted Acc\n"
  ) +
  theme_classic()
```

## 3.2. Study 1 

Model fit of the Flanker was done the same as in the Pilot.
Figure SX and Figure SX show the model fit based on simulated data.
We found good model fit across all three conditions, both for RTs as well as accuracy rates.

<br>

```{r}
#| label: figureS11
#| dpi: 600
#| fig.width: 7
#| fig.height: 7
#| fig-cap: | 
#|   **Figure S11.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
study1_ssp_fit_rt
```

<br>

```{r}
#| label: figureS12
#| dpi: 600
#| fig.width: 7
#| fig-cap: | 
#|   **Figure S12.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
study1_ssp_fit_acc
```

<br>

## 3.3. Study 2 

### 3.3.1 Flanker 

Model fit of the Flanker was done the same as in the Pilot and Study 1.
Figure SX and Figure SX show the model fit based on simulated data.
We found good model fit, both for RTs as well as accuracy rates.

```{r}
#| label: figureS13
#| dpi: 600
#| fig.width: 7
#| fig-cap: | 
#|   **Figure S13.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
study2_ssp_fit_rt
```

<br>

```{r}
#| label: figureS14
#| dpi: 600
#| fig.width: 7
#| fig-cap: | 
#|   **Figure S14.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse.
study2_ssp_fit_acc
```

### 3.3.2 Global-Local Task


# Section 4. Deviations from preregistrations

In this section, we provide a numbered overview of the deviations from the preregistration in each study.

## 4.1. Pilot 

1. *DDM estimation using Hierarchical Bayesian DDM instead of Maximum Likelihood estimation.* The rational for this change is explained in more detail in section 3.1.1.

2. *Focus on Flanker Interference instead of separate attention parameters.* The SSP model provides two parameters representing attentional processes: (1) the initial attention width, and (2) the rate at which attention shrinks towards the central target. 
We had initially planned to analyze both parameters separately.
However, after analyzing the data from Study 1, we realized that the estimates of these two parameters separately were very unstable.
We noticed this when plotting the within-person estimates between conditions (standard, enhanced, and degraded) against each other.
Figure SX provides an overview of these correlations for attentional width, shrinking rate, interference, and, for illustrative purposes, the RT difference score.
We consider the comparison between the standard and enhanced condition the most informative, as the stimuli in these conditions were most similar.
The within-person correlations between conditions of attentional width and shrinking were very low.
However, the correlations were substantially higher for interference (which even outperformed the standard RT difference scores, as typically used in traditional assessments).
Thus, we decided to use the Interference estimate in our analyses across all studies.

```{r}
#| label: figureS15
#| fig-width: 7
#| fig-height: 8
#| dpi: 600
#| fig-cap: | 
#|   **Figure S15. **Within-person bivarate correlations between Flanker conditions in Study 2 for RT differences, attentional width, shrinking rate, and interference.
study1_ssp_cor_plot
```

3. 

## 4.2. Study 1 

1. In our preregistration of Study 1, we preregistered four exploratory (hypothesis-generating) aims, which were unrelated to the primary (hypothesis-driven) aims described in the main manuscript. These were: (1) Investigating the factor structure of unpredictability measures and comparing it to the structure found in the Pilot; (2) Exploring the role of state anxiety, hunger, and sleep deprivation as potential moderators of the relationship between adversity and attention performance; (3) Exploring bivariate correlations between measures of adversity, attention, and measures of temporal orientation; (4) Explore the correlation between current depressive symptoms and retrospective measures of adversity. The results of aim 1 are described in Section 2.1.2. The 

## 4.3. Study 2 

2. *Global-Local performance.* In the original preregistration, we specified that we would exclude participants who performed at chance on either the Flanker Task or the Global-Local Task, which was defined as an accuracy of 59.4% or lower.
However, initial inspections of the Global-Local Task data showed that a substantial part of the sample did not reach this cut-off, suggesting that the task was more difficult than anticipated.
Thus, we developed a more fine-grained approach (described below) in an attempt to distinguish between 1) participants who did not understand the task and 2) participants who understood the task, but found it difficult to perform well. 
Given the assumptions of DDM, the first group would have to be excluded because they likely did not go through a process of information accumulation.
However, the model should be able to adequately fit the data of the second group.

The amended analysis approach for the Global-Local Task looked as follows: (1) Fit the data to the cleaned data of the full sample, including participants who performed at or below chance level (i.e., after trial-level exclusions but before case-wise exclusions); (2) Based on recovered parameter estimates for each participant, simulate the same number of trials (reaction times and accuracy) using the `RWiener` package, separately for Global and Local trials. (3) For each participant, calculate the 25th, 50th and 75th quantile of both their real RTs and the simulated RTs. 
In addition, we calculate mean accuracies based on the real and simulated data. (4) Compute standardized residuals between the real and simulated data for RTs at each quantile and for accuracy.
In case of good fit, the residual should be close to zero. (5) Exclude the data of participants with any standardized residual > 3.2 SD.

3. *Multiverse analysis.* In the preregistration, we planned to include three variables as covariates that were previously featured as arbitrary exclusion decisions in the multiverse specification: 1) whether or not participants rescaled the screen; 2) whether or not participants exited fullscreen mode at some point during the tasks; 3) Whether or not participants experienced interruptions during the tasks.
Our reasoning was that these three factors were consistently found to have a large impact on model results.
However, we realized later on that adding these factors as covariates was not a good approach from a causal inference standpoint.
That is, it is more likely that each of these factors added random noise to our estimates than that they had a causal effect on the outcome.
Therefore, we decided instead to include these factors as arbitrary decisions in the multiverse analyses, similarly as the previous two studies.
This allowed for a coherent assessment of influential factors across all three experiments.


# Section 5. Multiverse analysis.

In this section, we provide additional results of the multiverse analyses.
Specifically, we report (1) the distributions of *p*-values across the multiverses and (2) influential data cleaning decisions.

## 5.1. Pilot

Figure XX and Figure XX present *p*-distributions and the explained variance of each data cleaning decision in the variation in effect sizes for the results presented in Table 3 in the main text.

```{r}
#| label: figureS16
#| fig.width: 7
#| fig.height: 10
#| dpi: 600
#| fig-cap: | 
#|   **Figure S16.** Multiverse p-value distributions belonging to the analyses reported in Table 3 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse. Panel A: Cued Attention Task. Panel B: Change Detection Task. Panel C: Flanker Task.
(
  (pilot_prim_lmer_pvalues_plot$cueing_rt + labs(title = "Raw response time", tag = "A", y = "") + theme_classic()) + 
    (pilot_prim_lmer_pvalues_plot$cueing_hddm_v + labs(title = "Drift rate", y = "") + theme_classic()) + 
    (pilot_prim_lm_pvalues_plot$cueing_fixed_hddm_a + labs(title = "Boundary separation", y = "") + theme_classic()) + 
    (pilot_prim_lmer_pvalues_plot$cueing_hddm_t + labs(title = "Non-decision time", y = "") + theme_classic())
) /
  (
    (pilot_prim_lm_pvalues_plot$rt_change + labs(title = "Raw response time", tag = "B", y = "") + theme_classic()) + 
      (pilot_prim_lm_pvalues_plot$change_hddm_v + labs(title = "Drift rate", y = "") + theme_classic()) + 
      (pilot_prim_lm_pvalues_plot$change_hddm_a + labs(title = "Boundary separation", y = "") + theme_classic()) + 
      (pilot_prim_lm_pvalues_plot$change_hddm_t + labs(title = "Non-decision time", y = "") + theme_classic())
  ) /
  (
    (pilot_prim_lmer_pvalues_plot$flanker_rt + labs(title = "Raw response time", tag = "C", y = "") + theme_classic()) + 
      (pilot_prim_lm_pvalues_plot$flanker_ssp_p + labs(title = "Perceptual input", y = "") + theme_classic()) + 
      (pilot_prim_lm_pvalues_plot$flanker_ssp_interference + labs(title = "Interference", y = "") + theme_classic()) + 
      (pilot_prim_lm_pvalues_plot$flanker_ssp_a + labs(title = "Boundary separation", y = "") + theme_classic()) +
      (pilot_prim_lm_pvalues_plot$flanker_ssp_t + labs(title = "Non-decision time", y = "") + theme_classic())
  ) 
```


```{r}
#| include: false
#| echo: false
f17_p1 <- pilot_prim_lmer_variance_plot$cueing_rt + labs(title = "Raw response time", tag = "A", y = "", fill = "")
f17_p2 <- pilot_prim_lmer_variance_plot$cueing_hddm_v + labs(title = "Drift rate", y = "") + guides(fill = "none")
f17_p3 <- pilot_prim_lm_variance_plot$cueing_fixed_hddm_a + labs(title = "Boundary separation", y = "") + guides(fill = "none") 
f17_p4 <- pilot_prim_lmer_variance_plot$cueing_hddm_t + labs(title = "Non-decision time", y = "") + guides(fill = "none")

f17_p5 <- pilot_prim_lm_variance_plot$rt_change + labs(title = "Raw response time", tag = "B", y = "") + guides(fill = "none") 
f17_p6 <- pilot_prim_lm_variance_plot$change_hddm_v + labs(title = "Drift rate", y = "") + guides(fill = "none") 
f17_p7 <- pilot_prim_lm_variance_plot$change_hddm_a + labs(title = "Boundary separation", y = "") + guides(fill = "none")
f17_p8 <- pilot_prim_lm_variance_plot$change_hddm_t + labs(title = "Non-decision time", y = "") + guides(fill = "none") 

f17_p9 <- pilot_prim_lmer_variance_plot$flanker_rt + labs(title = "Raw response time", tag = "C", y = "") + guides(fill = "none")
f17_p10 <- pilot_prim_lm_variance_plot$flanker_ssp_p + labs(title = "Perceptual input", y = "") + guides(fill = "none") 
f17_p11 <- pilot_prim_lm_variance_plot$flanker_ssp_interference + labs(title = "Interference", y = "") + guides(fill = "none") 
f17_p12 <- pilot_prim_lm_variance_plot$flanker_ssp_a + labs(title = "Boundary separation", y = "") + guides(fill = "none") 
f17_p13 <- pilot_prim_lm_variance_plot$flanker_ssp_t + labs(title = "Non-decision time", y = "") + guides(fill = "none")

align_patches(f17_p1,f17_p2,f17_p3,f17_p4,f17_p5,f17_p6,f17_p7,f17_p8,f17_p9,f17_p10,f17_p11,f17_p12,f17_p13)
```

```{r}
#| label: figureS17
#| fig.width: 7
#| fig.height: 10
#| dpi: 600
#| fig-cap: | 
#|   **Figure S17.** Multiverse explained variance of each data cleaning decision belonging to the analyses reported in Table 3 in the main text. Panel A: Cued Attention Task. Panel B: Change Detection Task. Panel C: Flanker Task.
final_plot_S17 <- 
  (f17_p1+f17_p2+f17_p3+f17_p4 + plot_layout(ncol = 3)) /
  (f17_p5+f17_p6+f17_p7+f17_p8 + plot_layout(ncol = 3)) /
  (f17_p9+f17_p10+f17_p11+f17_p12+f17_p13 + plot_layout(ncol = 3)) + 
  plot_layout(guides = "collect") & theme(legend.position='bottom')

final_plot_S17

```

## 5.2 Study 1

Figure XX and Figure XX present *p*-distributions and the explained variance of each data cleaning decision in the variation in effect sizes for the results presented in Table 4 in the main text.

```{r}
#| label: figureS18
#| fig.width: 7
#| fig.height: 10
#| dpi: 600
#| fig-cap: | 
#|   **Figure S18.** Multiverse p-value distributions belonging to the analyses reported in Table 4 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse. Panel A: Analyses involving violence exposure (hypothesis-driven). Panel B: Analyses involving unpredictability (exploratory).
(
  (study1_prim_ssp_pvalues_plot_study1$rt_diff + labs(title = "RT difference", tag = "A", y = "") + theme_classic()) + 
    (study1_prim_ssp_pvalues_plot_study1$p_flanker + labs(title = "Perceptual input", y = "") + theme_classic()) + 
    (study1_prim_ssp_pvalues_plot_study1$interference_flanker + labs(title = "Interference", y = "") + theme_classic()) + 
    (study1_prim_ssp_pvalues_plot_study1$a_flanker + labs(title = "Boundary separation", y = "") + theme_classic()) +
    (study1_prim_ssp_pvalues_plot_study1$t0_flanker + labs(title = "Non-decision time", y = "") + theme_classic())
) /
  (
    (study1_expl_ssp_pvalues_plot_study1$rt_diff + labs(title = "RT difference", tag = "B", y = "") + theme_classic()) + 
      (study1_expl_ssp_pvalues_plot_study1$p_flanker + labs(title = "Perceptual input", y = "") + theme_classic()) + 
      (study1_expl_ssp_pvalues_plot_study1$interference_flanker + labs(title = "Interference", y = "") + theme_classic()) + 
      (study1_expl_ssp_pvalues_plot_study1$a_flanker + labs(title = "Boundary separation", y = "") + theme_classic()) +
      (study1_expl_ssp_pvalues_plot_study1$t0_flanker + labs(title = "Non-decision time", y = "") + theme_classic())
  )
```

```{r}
#| include: false
#| echo: false
f19_p1 <- study1_prim_ssp_variance_plot_study1$rt_diff + labs(title = "RT difference", tag = "A", y = "", fill = "")
f19_p2 <- study1_prim_ssp_variance_plot_study1$p_flanker + labs(title = "Perceptual input", y = "") + guides(fill = "none") 
f19_p3 <- study1_prim_ssp_variance_plot_study1$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none") 
f19_p4 <- study1_prim_ssp_variance_plot_study1$a_flanker + labs(title = "Boundary separation", y = "") + guides(fill = "none") 
f19_p5 <- study1_prim_ssp_variance_plot_study1$t0_flanker + labs(title = "Non-decision time", y = "") + guides(fill = "none") 

f19_p6 <- study1_expl_ssp_variance_plot_study1$rt_diff + labs(title = "RT difference", tag = "B", y = "") + guides(fill = "none") 
f19_p7 <- study1_expl_ssp_variance_plot_study1$p_flanker + labs(title = "Perceptual input", y = "") + guides(fill = "none")
f19_p8 <- study1_expl_ssp_variance_plot_study1$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none")
f19_p9 <- study1_expl_ssp_variance_plot_study1$a_flanker + labs(title = "Boundary separation", y = "") + guides(fill = "none") 
f19_p10 <- study1_expl_ssp_variance_plot_study1$t0_flanker + labs(title = "Non-decision time", y = "") + guides(fill = "none") 


align_patches(f19_p1,f19_p2,f19_p3,f19_p4,f19_p5,f19_p6,f19_p7,f19_p8,f19_p9,f19_p10)
```

```{r}
#| label: figureS19
#| fig.width: 7
#| fig.height: 10
#| dpi: 600
#| fig-cap: | 
#|   **Figure S19.** Multiverse explained variance of each data cleaning decision belonging to the analyses reported in Table 4 in the main text. Panel A: Analyses involving violence exposure (hypothesis-driven). Panel B: Analyses involving unpredictability (exploratory).
final_plot_S19 <- 
  (f19_p1+f19_p2+f19_p3+f19_p4+f19_p5 + plot_layout(ncol = 3)) /
  (f19_p6+f19_p7+f19_p8+f19_p9+f19_p10 + plot_layout(ncol = 3)) +
  plot_layout(guides = "collect") & theme(legend.position='bottom')

final_plot_S19

```



```{r}
#| label: figureS20
#| fig.width: 7
#| fig.height: 10
#| dpi: 600
#| fig-cap: | 
#|   **Figure S20.** Multiverse p-value distributions belonging to the interaction effects involving violence exposure reported in Table 5 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse. Panel A: Analyses comparing the enhanced condition to the standard condition. Panel B: Analyses comparing the degraded condition to the standard condition.
(
  (study1_prim_ssp_enh_pvalues_plot$rt_diff + labs(title = "RT difference", tag = "A", x = "p", y = "") + theme_classic()) + 
    (study1_prim_ssp_enh_pvalues_plot$p_flanker + labs(title = "Perceptual input", x = "p", y = "") + theme_classic()) + 
    (study1_prim_ssp_enh_pvalues_plot$interference_flanker + labs(title = "Interference", x = "p", y = "") + theme_classic()) + 
    (study1_prim_ssp_enh_pvalues_plot$a_flanker + labs(title = "Boundary separation", x = "p", y = "") + theme_classic()) +
    (study1_prim_ssp_enh_pvalues_plot$t0_flanker + labs(title = "Non-decision time", x = "p", y = "") + theme_classic())
) /
  (
    (study1_prim_ssp_deg_pvalues_plot$rt_diff + labs(title = "RT difference", tag = "B", x = "p", y = "") + theme_classic()) + 
    (study1_prim_ssp_deg_pvalues_plot$p_flanker + labs(title = "Perceptual input", x = "p", y = "") + theme_classic()) + 
    (study1_prim_ssp_deg_pvalues_plot$interference_flanker + labs(title = "Interference", x = "p", y = "") + theme_classic()) + 
    (study1_prim_ssp_deg_pvalues_plot$a_flanker + labs(title = "Boundary separation", x = "p", y = "") + theme_classic()) +
    (study1_prim_ssp_deg_pvalues_plot$t0_flanker + labs(title = "Non-decision time", x = "p", y = "") + theme_classic())
  )
```


```{r}
#| include: false
#| echo: false
f21_p1 <- study1_prim_ssp_enh_variance_plot$rt_diff + labs(title = "RT difference", tag = "A", y = "", fill = "")
f21_p2 <- study1_prim_ssp_enh_variance_plot$p_flanker + labs(title = "Perceptual input", y = "") + guides(fill = "none") 
f21_p3 <- study1_prim_ssp_enh_variance_plot$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none") 
f21_p4 <- study1_prim_ssp_enh_variance_plot$a_flanker + labs(title = "Boundary separation", y = "") + guides(fill = "none") 
f21_p5 <- study1_prim_ssp_enh_variance_plot$t0_flanker + labs(title = "Non-decision time", y = "") + guides(fill = "none") 

f21_p6 <- study1_prim_ssp_deg_variance_plot$rt_diff + labs(title = "RT difference", tag = "B", y = "") + guides(fill = "none") 
f21_p7 <- study1_prim_ssp_deg_variance_plot$p_flanker + labs(title = "Perceptual input", y = "") + guides(fill = "none")
f21_p8 <- study1_prim_ssp_deg_variance_plot$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none") 
f21_p9 <- study1_prim_ssp_deg_variance_plot$a_flanker + labs(title = "Boundary separation", y = "") + guides(fill = "none") 
f21_p10 <- study1_prim_ssp_deg_variance_plot$t0_flanker + labs(title = "Non-decision time", y = "") + guides(fill = "none")


align_patches(f21_p1,f21_p2,f21_p3,f21_p4,f21_p5,f21_p6,f21_p7,f21_p8,f21_p9,f21_p10)
```

```{r}
#| label: figureS21
#| fig.width: 7
#| fig.height: 10
#| dpi: 600
#| fig-cap: | 
#|   **Figure S21.** Multiverse explained variance of each data cleaning decision belonging to the interaction effects involving violence exposure reported in Table 5 in the main text. Panel A: Analyses comparing the enhanced condition to the standard condition. Panel B: Analyses comparing the degraded condition to the standard condition.
final_plot_S21 <- 
  (f21_p1+f21_p2+f21_p3+f21_p4+f21_p5 + plot_layout(ncol = 3)) /
  (f21_p6+f21_p7+f21_p8+f21_p9+f21_p10 + plot_layout(ncol = 3)) /
  plot_layout(guides = "collect") & theme(legend.position='bottom')

final_plot_S21

```


```{r}
#| label: figureS22
#| fig.width: 7
#| fig.height: 10
#| dpi: 600
#| fig-cap: | 
#|   **Figure S22.** Multiverse p-value distributions belonging to the interaction effects involving unpredictability reported in Table 5 in the main text. The dashed vertical line depicts the cut-off of .05. The percentages in the upper-right corners are the percentage of statistically significant analyses in multiverse. Panel A: Analyses comparing the enhanced condition to the standard condition. Panel B: Analyses comparing the degraded condition to the standard condition.
(
  (study1_expl_ssp_enh_pvalues_plot$rt_diff + labs(title = "RT difference", tag = "A", x = "p", y = "")) + theme_classic() + 
    (study1_expl_ssp_enh_pvalues_plot$p_flanker + labs(title = "Perceptual input", x = "p", y = "") + theme_classic()) + 
    (study1_expl_ssp_enh_pvalues_plot$interference_flanker + labs(title = "Interference", x = "p", y = "") + theme_classic()) + 
    (study1_expl_ssp_enh_pvalues_plot$a_flanker + labs(title = "Boundary separation", x = "p", y = "") + theme_classic()) +
    (study1_expl_ssp_enh_pvalues_plot$t0_flanker + labs(title = "Non-decision time", x = "p", y = "") + theme_classic())
) /
  (
    (study1_expl_ssp_deg_pvalues_plot$rt_diff + labs(title = "RT difference", tag = "B", x = "p", y = "") + theme_classic()) + 
    (study1_expl_ssp_deg_pvalues_plot$p_flanker + labs(title = "Perceptual input", x = "p", y = "") + theme_classic()) + 
    (study1_expl_ssp_deg_pvalues_plot$interference_flanker + labs(title = "Interference", x = "p", y = "") + theme_classic()) + 
    (study1_expl_ssp_deg_pvalues_plot$a_flanker + labs(title = "Boundary separation", x = "p", y = "") + theme_classic()) +
    (study1_expl_ssp_deg_pvalues_plot$t0_flanker + labs(title = "Non-decision time", x = "p", y = "") + theme_classic())
  )
```

```{r}
#| include: false
#| echo: false
f23_p1 <- study1_expl_ssp_enh_variance_plot$rt_diff + labs(title = "RT difference", tag = "A", y = "", fill = "") 
f23_p2 <- study1_expl_ssp_enh_variance_plot$p_flanker + labs(title = "Perceptual input", y = "") + guides(fill = "none")
f23_p3 <- study1_expl_ssp_enh_variance_plot$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none")
f23_p4 <- study1_expl_ssp_enh_variance_plot$a_flanker + labs(title = "Boundary separation", y = "") + guides(fill = "none")
f23_p5 <- study1_expl_ssp_enh_variance_plot$t0_flanker + labs(title = "Non-decision time", y = "") + guides(fill = "none")

f23_p6 <- study1_expl_ssp_deg_variance_plot$rt_diff + labs(title = "RT difference", tag = "B", y = "") + guides(fill = "none") 
f23_p7 <- study1_expl_ssp_deg_variance_plot$p_flanker + labs(title = "Perceptual input", y = "") + guides(fill = "none")
f23_p8 <- study1_expl_ssp_deg_variance_plot$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none") 
f23_p9 <- study1_expl_ssp_deg_variance_plot$a_flanker + labs(title = "Boundary separation", y = "") + guides(fill = "none") 
f23_p10 <- study1_expl_ssp_deg_variance_plot$t0_flanker + labs(title = "Non-decision time", y = "") + guides(fill = "none") 


align_patches(f23_p1,f23_p2,f23_p3,f23_p4,f23_p5,f23_p6,f23_p7,f23_p8,f23_p9,f23_p10)
```

```{r}
#| label: figureS23
#| fig.width: 7
#| fig.height: 10
#| dpi: 600
#| fig-cap: | 
#|   **Figure S23.** Multiverse explained variance of each data cleaning decision belonging to the interaction effects involving unpredictability reported in Table 5 in the main text. Panel A: Analyses comparing the enhanced condition to the standard condition. Panel B: Analyses comparing the degraded condition to the standard condition.
final_plot_S23 <- 
  (f23_p1+f23_p2+f23_p3+f23_p4+f23_p5 + plot_layout(ncol = 3)) /
  (f23_p6+f23_p7+f23_p8+f23_p9+f23_p10 + plot_layout(ncol = 3)) /
  plot_layout(guides = "collect") & theme(legend.position='bottom')

final_plot_S23

```


## 5.3 Study 2

```{r}
#| label: figureS24
#| fig.width: 7
#| fig.height: 10
#| dpi: 600
#| fig-cap: | 
#|   **Figure S24.** Multiverse p-value distributions belonging to the associations between violence exposure with perceptual input and interference in the Pilot, Study 1, Study 2, and pooled across all studies, as reported in Figure 2 in the main text. 
(
  (pilot_prim_lm_pvalues_plot$flanker_ssp_p + labs(title = "Perceptual input", tag = "Pilot", y = "", x = "p") + theme_classic()) + 
    (pilot_prim_lm_pvalues_plot$flanker_ssp_interference + labs(title = "Interference", y = "", x = "p") + theme_classic()) 
) /
  (
    (study1_prim_ssp_pvalues_plot_study1$p_flanker + labs(title = "Perceptual input", tag = "Study 1", y = "", x = "p") + theme_classic()) + 
    (study1_prim_ssp_pvalues_plot_study1$interference_flanker + labs(title = "Interference", y = "", x = "p") + theme_classic()) 
  ) /
  (
    (study2_prim_aim1_pvalues_plot_study2$p_flanker.vio_comp + labs(title = "Perceptual input", tag = "Study 2", y = "") + theme_classic()) + 
    (study2_prim_aim1_pvalues_plot_study2$interference_flanker.vio_comp + labs(title = "Interference", y = "") + theme_classic()) 
  ) /
  (
    (study2_aim1_ssp_pooled_pvalues_plot$vio_comp_p_flanker + labs(title = "Perceptual input", tag = "Pooled", y = "") + theme_classic()) + 
    (study2_aim1_ssp_pooled_pvalues_plot$vio_comp_interference_flanker + labs(title = "Interference", y = "") + theme_classic()) 
  )
```


```{r}
#| label: figureS25
#| fig.width: 7
#| fig.height: 10
#| dpi: 600
#| fig-cap: | 
#|   **Figure S25.** Multiverse explained variance of each data cleaning decision belonging to the associations between violence exposure with perceptual input and interference in the Pilot, Study 1, Study 2, and pooled across all studies, as reported in Figure 2 in the main text. 
(
  (pilot_prim_lm_variance_plot$flanker_ssp_p + labs(title = "Perceptual input", tag = "Pilot", fill = "", y = "")) + 
    (pilot_prim_lm_variance_plot$flanker_ssp_interference + labs(title = "Interference", y = "") + guides(fill = "none")) 
) /
  (
    (study1_prim_ssp_variance_plot_study1$p_flanker + labs(title = "Perceptual input", tag = "Study 1", y = "") + guides(fill = "none")) + 
    (study1_prim_ssp_variance_plot_study1$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none")) 
  ) /
  (
    (study2_prim_aim1_variance_plot_study2$p_flanker.vio_comp + labs(title = "Perceptual input", tag = "Study 2", y = "") + guides(fill = "none")) + 
    (study2_prim_aim1_variance_plot_study2$interference_flanker.vio_comp + labs(title = "Interference", y = "") + guides(fill = "none")) 
  ) /
  (
    (study2_prim_aim1_variance_plot$p_flanker.vio_comp + labs(title = "Perceptual input", tag = "Pooled", y = "") + guides(fill = "none")) + 
    (study2_prim_aim1_variance_plot$interference_flanker.vio_comp + labs(title = "Interference", y = "") + guides(fill = "none")) 
  ) + plot_layout(guides = "collect") & theme(legend.position='bottom')
```


```{r}
#| label: figureS26
#| fig.width: 7
#| fig.height: 10
#| dpi: 600
#| fig-cap: | 
#|   **Figure S26.** Multiverse p-value distributions belonging to the associations between unpredictability with perceptual input and interference in the Pilot, Study 1, Study 2, and pooled across all studies, as reported in Figure 3 in the main text. 
(
  (pilot_expl_lm_pvalues_plot$flanker_ssp_p + labs(title = "Perceptual input", tag = "Pilot", y = "", x = "p") + theme_classic()) + 
    (pilot_expl_lm_pvalues_plot$flanker_ssp_interference + labs(title = "Interference", y = "", x = "p") + theme_classic()) 
) /
  (
    (study1_expl_ssp_pvalues_plot_study1$p_flanker + labs(title = "Perceptual input", tag = "Study 1", y = "", x = "p") + theme_classic()) + 
    (study1_expl_ssp_pvalues_plot_study1$interference_flanker + labs(title = "Interference", y = "", x = "p") + theme_classic()) 
  ) /
  (
    (study2_prim_aim1_pvalues_plot_study2$p_flanker.unp_comp + labs(title = "Perceptual input", tag = "Study 2", y = "") + theme_classic()) + 
    (study2_prim_aim1_pvalues_plot_study2$interference_flanker.unp_comp + labs(title = "Interference", y = "") + theme_classic()) 
  ) /
  (
    (study2_prim_aim1_pvalues_plot$p_flanker.unp_comp + labs(title = "Perceptual input", tag = "Pooled", y = "") + theme_classic()) + 
    (study2_prim_aim1_pvalues_plot$interference_flanker.unp_comp + labs(title = "Interference", y = "") + theme_classic()) 
  )
```


```{r}
#| label: figureS27
#| fig.width: 7
#| fig.height: 10
#| dpi: 600
#| fig-cap: | 
#|   **Figure S27.** Multiverse explained variance of each data cleaning decision belonging to the associations between unpredictability with perceptual input and interference in the Pilot, Study 1, Study 2, and pooled across all studies, as reported in Figure 3 in the main text. 
(
  (pilot_expl_lm_variance_plot$flanker_ssp_p + labs(title = "Perceptual input", fill = "", tag = "Pilot", y = "")) + 
    (pilot_expl_lm_variance_plot$flanker_ssp_interference + labs(title = "Interference", y = "") + guides(fill = "none")) 
) /
  (
    (study1_expl_ssp_variance_plot_study1$p_flanker + labs(title = "Perceptual input", tag = "Study 1", y = "") + guides(fill = "none")) + 
    (study1_expl_ssp_variance_plot_study1$interference_flanker + labs(title = "Interference", y = "") + guides(fill = "none")) 
  ) /
  (
    (study2_prim_aim1_variance_plot_study2$p_flanker.unp_comp + labs(title = "Perceptual input", tag = "Study 2", y = "") + guides(fill = "none")) + 
    (study2_prim_aim1_variance_plot_study2$interference_flanker.unp_comp + labs(title = "Interference", y = "") + guides(fill = "none")) 
  ) /
  (
    (study2_prim_aim1_variance_plot$p_flanker.unp_comp + labs(title = "Perceptual input", tag = "Pooled", y = "") + guides(fill = "none")) + 
    (study2_prim_aim1_variance_plot$interference_flanker.unp_comp + labs(title = "Interference", y = "") + guides(fill = "none")) 
  ) + plot_layout(guides = "collect") & theme(legend.position='bottom')
```

